{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T09:29:43.880303Z",
     "iopub.status.busy": "2024-05-28T09:29:43.880105Z",
     "iopub.status.idle": "2024-05-28T09:29:46.412832Z",
     "shell.execute_reply": "2024-05-28T09:29:46.411704Z",
     "shell.execute_reply.started": "2024-05-28T09:29:43.880282Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import gc\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from diffusers import DDIMScheduler\n",
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor, Lambda\n",
    "from IPython.display import clear_output\n",
    "from tqdm import trange\n",
    "\n",
    "from src import distributions\n",
    "from src.mnistm_utils import MNISTM\n",
    "from src.guided_samplers import PairedSubsetSampler, SubsetGuidedDataset, get_indicies_subset\n",
    "\n",
    "from src.cunet import CUNet\n",
    "from src.enot import SDE, integrate\n",
    "from src.resnet2 import ResNet_D\n",
    "\n",
    "from src.new_plotters import plot_fixed_linked_sdes_images, plot_random_linked_sdes_images\n",
    "\n",
    "from src.tools import freeze, unfreeze, weights_init_D\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.guided_samplers import Sampler, PairedSubsetSampler\n",
    "\n",
    "\n",
    "class PairedPlotSampler(Sampler):\n",
    "    def __init__(self, loader, subsetsize = 8, weight=None, device='cuda'):\n",
    "        super(PairedPlotSampler, self).__init__(device)\n",
    "        self.loader = loader\n",
    "        self.subsetsize = subsetsize\n",
    "        if weight is None:\n",
    "            weight = [1/self.loader.num_classes for _ in range(self.loader.num_classes)]\n",
    "        self.weight = weight\n",
    "        \n",
    "    def sample(self):\n",
    "        classes = np.array(list(range(0,10)))\n",
    "        batch_X = []\n",
    "        batch_Y = []\n",
    "        with torch.no_grad():\n",
    "            for class_ in classes: \n",
    "                X, Y = self.loader.get(class_, self.subsetsize)\n",
    "                batch_X.append(X.clone().to(self.device).float())\n",
    "                batch_Y.append(Y.clone().to(self.device).float())\n",
    "        return torch.stack(batch_X).to(self.device), torch.stack(batch_Y).to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.fid_score import calculate_frechet_distance\n",
    "from src.tools import compute_transport_accuracy, compute_transport_accuracy_and_FID, get_linked_sdes_pushed_loader_stats, linked_mapping\n",
    "\n",
    "\n",
    "def plot_transport_results(X, Y, SDEs, m_data=None, s_data=None, XY_test_sampler=None, classifier=None, metrics=False):\n",
    "    FID = []\n",
    "    accuracies = []\n",
    "    fig, axes = plt.subplots(3, 10, figsize=(9, 3.5), dpi=150)\n",
    "    axes[0, 0].set_ylabel('$x \\sim \\mathbb{P}_n$', fontsize=18)\n",
    "    axes[1, 0].set_ylabel('$y \\sim \\mathbb{Q}_n$', fontsize=18)\n",
    "    images = [X, Y]\n",
    "    labels = ['$\\mathcal{F}_{G}$ \\n (ours)', '$\\mathcal{F}_{G}$ \\n (ours)']\n",
    "    \n",
    "    for sde in SDEs:\n",
    "        freeze(sde)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        T_X = linked_mapping(SDEs, X)\n",
    "        images.append(T_X)\n",
    "    axes[2, 0].set_ylabel(\"{}\".format(labels[0]), fontsize=20)\n",
    "    \n",
    "    if metrics:\n",
    "        print('Method: DiffOT')\n",
    "        accuracy, fid = compute_transport_accuracy_and_FID(SDEs, XY_test_sampler,\n",
    "                                                            classifier, m_data, s_data)\n",
    "        print(f\"Accuracy: {accuracy}\\nFID: {fid}\")\n",
    "        FID.append(fid)\n",
    "        accuracies.append(accuracy)\n",
    "            \n",
    "    x_titles = [0,1,2,3,4,5,6,7,8,9]\n",
    "    for i, title in enumerate(x_titles):\n",
    "        axes[0,i].set_title(r'${}$'.format(title), fontsize=20)\n",
    "    imgs = torch.cat(images).to('cpu').permute(0,2,3,1).mul(0.5).add(0.5).numpy().clip(0,1)\n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        ax.imshow(imgs[i], cmap='Greys')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    fig.tight_layout(pad=0.001)\n",
    "    plt.show()\n",
    "    return FID, accuracies, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T09:29:46.414432Z",
     "iopub.status.busy": "2024-05-28T09:29:46.414012Z",
     "iopub.status.idle": "2024-05-28T09:29:46.420313Z",
     "shell.execute_reply": "2024-05-28T09:29:46.419263Z",
     "shell.execute_reply.started": "2024-05-28T09:29:46.414402Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE_IDS = [0]\n",
    "\n",
    "NUM_LABELED = 10\n",
    "SUBSET_WEIGHTS = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "DATASET = 'fmnist2mnist'\n",
    "DATASET_PATH = '~/data/'\n",
    "IMG_SIZE = 32\n",
    "CHANNELS = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T09:29:46.422080Z",
     "iopub.status.busy": "2024-05-28T09:29:46.421789Z",
     "iopub.status.idle": "2024-05-28T09:29:46.428673Z",
     "shell.execute_reply": "2024-05-28T09:29:46.428098Z",
     "shell.execute_reply.started": "2024-05-28T09:29:46.422052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXP_NAME = 'Adapt_fmnist2mnist_pivotal_0_20_50_100_20240606-200021'\n",
      "LOAD_PATH = '../logs/Adapt_fmnist2mnist_pivotal_0_20_50_100_20240606-200021/'\n"
     ]
    }
   ],
   "source": [
    "# change below 3 variables to get real EXP_NAME\n",
    "STRATEGY = \"Adapt\"  # [Normal|Fix|Adapt]\n",
    "PIVOTAL_LIST = [0, 20, 50, 100]\n",
    "TIME = \"20240606-200021\" # \"20240526-134124\"\n",
    "\n",
    "EXP_NAME = f\"{STRATEGY}_{DATASET}_pivotal_{'_'.join(map(str, PIVOTAL_LIST))}_{TIME}\"\n",
    "LOAD_PATH = f\"../logs/{EXP_NAME}/\"\n",
    "\n",
    "print(f\"{EXP_NAME = }\")\n",
    "\n",
    "# LOAD_PATH = \"../logs/weights/epl_1/\"\n",
    "print(f\"{LOAD_PATH = }\")\n",
    "\n",
    "\n",
    "with open(os.path.join(LOAD_PATH, \"config.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    CONFIG = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T09:29:48.599404Z",
     "iopub.status.busy": "2024-05-28T09:29:48.598616Z",
     "iopub.status.idle": "2024-05-28T09:29:48.722433Z",
     "shell.execute_reply": "2024-05-28T09:29:48.721292Z",
     "shell.execute_reply.started": "2024-05-28T09:29:48.599354Z"
    }
   },
   "outputs": [],
   "source": [
    "EPSILON = CONFIG[\"EPSILON\"]\n",
    "\n",
    "N_STEPS = CONFIG[\"N_STEPS\"]\n",
    "# SUBSET_WEIGHTS = CONFIG[\"SUBSET_WEIGHTS\"]\n",
    "BATCH_SIZE = CONFIG[\"BATCH_SIZE\"]\n",
    "SUBSET_SIZE = CONFIG[\"SUBSET_SIZE\"]\n",
    "DIFFUSION_STEPS = CONFIG[\"DIFFUSION_STEPS\"]\n",
    "PIVOTAL_LIST = CONFIG[\"PIVOTAL_LIST\"]\n",
    "OUTER_ITERS = CONFIG[\"OUTER_ITERS\"]\n",
    "\n",
    "\n",
    "IMG_SIZE = CONFIG[\"IMG_SIZE\"]\n",
    "UNET_BASE_FACTOR = CONFIG[\"UNET_BASE_FACTOR\"]\n",
    "\n",
    "TIME_DIM = CONFIG[\"TIME_DIM\"]\n",
    "USE_POSITIONAL_ENCODING = CONFIG[\"USE_POSITIONAL_ENCODING\"]\n",
    "\n",
    "PREDICT_SHIFT = CONFIG[\"PREDICT_SHIFT\"]\n",
    "\n",
    "USE_GRADIENT_CHECKPOINT = CONFIG[\"USE_GRADIENT_CHECKPOINT\"]\n",
    "N_LAST_STEPS_WITHOUT_NOISE = CONFIG[\"N_LAST_STEPS_WITHOUT_NOISE\"]\n",
    "IMAGE_INPUT = CONFIG[\"IMAGE_INPUT\"]\n",
    "FID_EPOCHS = CONFIG[\"FID_EPOCHS\"]\n",
    "\n",
    "SEED = CONFIG[\"SEED\"]\n",
    "assert torch.cuda.is_available()\n",
    "torch.cuda.set_device(f\"cuda:{DEVICE_IDS[0]}\")\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data for plot, accuracy, and FID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initalize data sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T09:29:51.377708Z",
     "iopub.status.busy": "2024-05-28T09:29:51.376839Z",
     "iopub.status.idle": "2024-05-28T09:29:56.957905Z",
     "shell.execute_reply": "2024-05-28T09:29:56.957344Z",
     "shell.execute_reply.started": "2024-05-28T09:29:51.377649Z"
    }
   },
   "outputs": [],
   "source": [
    "source_subset = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7 ,8, 9])\n",
    "new_labels_source = {0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:8, 9:9}\n",
    "target_subset = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "new_labels_target = {0:0, 1:1, 2:2, 3:3, 4:4, 5:5, 6:6, 7:7, 8:8, 9:9}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = models.resnet18()\n",
    "\n",
    "source_transform = Compose([\n",
    "    Resize((IMG_SIZE, IMG_SIZE)), \n",
    "    ToTensor(),\n",
    "    Normalize((0.5), (0.5)),\n",
    "])\n",
    "target_transform = source_transform\n",
    "\n",
    "if DATASET == 'mnist2kmnist':\n",
    "    source = datasets.MNIST\n",
    "    target = datasets.KMNIST\n",
    "    NC = 1\n",
    "    classifier.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    classifier.fc =  nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "    classifier.load_state_dict(torch.load('../saved_models/classifiers/kmnist.pt'))\n",
    "\n",
    "elif DATASET == 'fmnist2mnist':\n",
    "    source = datasets.FashionMNIST\n",
    "    target = datasets.MNIST\n",
    "    NC = 1\n",
    "    classifier.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    classifier.fc =  nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "    classifier.load_state_dict(torch.load('../saved_models/classifiers/mnist.pt'))\n",
    "\n",
    "    \n",
    "elif DATASET == 'mnist2usps':\n",
    "    source = datasets.MNIST\n",
    "    target = datasets.USPS\n",
    "    NC = 1\n",
    "    classifier.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    classifier.fc =  nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "    classifier.load_state_dict(torch.load('../saved_models/classifiers/usps.pt'))\n",
    "    \n",
    "\n",
    "elif DATASET == 'mnist2mnistm':\n",
    "    source = datasets.MNIST\n",
    "    target = MNISTM\n",
    "    NC = 3\n",
    "    classifier.fc =  nn.Linear(in_features=512, out_features=10, bias=True)\n",
    "    classifier.load_state_dict(torch.load('../saved_models/classifiers/mnistm.pt'))\n",
    "    source_transform = Compose([\n",
    "        Resize((IMG_SIZE, IMG_SIZE)), \n",
    "        ToTensor(),\n",
    "        Normalize((0.5), (0.5)), \n",
    "        Lambda(lambda x: -x.repeat(3,1,1))])\n",
    "    target_transform = Compose([\n",
    "        Resize(IMG_SIZE),\n",
    "        ToTensor(),\n",
    "        Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "classifier.cuda()\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Subclasses of Dataset should implement __getitem__.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 25\u001b[0m\n\u001b[1;32m     20\u001b[0m full_set \u001b[38;5;241m=\u001b[39m SubsetGuidedDataset(source_test, target_test, num_labeled\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, in_indicies \u001b[38;5;241m=\u001b[39m source_class_indicies, out_indicies \u001b[38;5;241m=\u001b[39m target_class_indicies)\n\u001b[1;32m     23\u001b[0m XY_test_sampler \u001b[38;5;241m=\u001b[39m PairedSubsetSampler(full_set, subsetsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, weight\u001b[38;5;241m=\u001b[39mSUBSET_WEIGHTS)\n\u001b[0;32m---> 25\u001b[0m m_data, s_data \u001b[38;5;241m=\u001b[39m \u001b[43mget_loader_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXY_test_sampler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_Y\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m m_data\u001b[38;5;241m.\u001b[39mshape, s_data\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/DiffOT/notebooks/../src/tools_paired.py:391\u001b[0m, in \u001b[0;36mget_loader_stats\u001b[0;34m(loader, batch_size, n_epochs, verbose, use_Y)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs)):\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 391\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/DiffOT/.venv/lib/python3.12/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/DiffOT/.venv/lib/python3.12/site-packages/torch/utils/data/dataset.py:61\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_co:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubclasses of Dataset should implement __getitem__.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Subclasses of Dataset should implement __getitem__."
     ]
    }
   ],
   "source": [
    "from src.tools_paired import get_loader_stats\n",
    "from src.guided_samplers import PairedSubsetSampler\n",
    "\n",
    "source_test = source(root=DATASET_PATH, train=False, download=True, transform=source_transform)\n",
    "source_test_subset_samples, labels, source_class_indicies = get_indicies_subset(source_test, \n",
    "                                                                    new_labels =new_labels_source,\n",
    "                                                                    classes=len(source_subset), \n",
    "                                                                    subset_classes=source_subset)\n",
    "source_test =  torch.utils.data.TensorDataset(torch.stack(source_test_subset_samples), torch.LongTensor(labels))\n",
    "\n",
    "\n",
    "target_test = target(root=DATASET_PATH, train=False, download=True, transform=target_transform)  \n",
    "target_test_subset_samples, target_labels, target_class_indicies = get_indicies_subset(target_test, \n",
    "                                                                                  new_labels = new_labels_target, \n",
    "                                                                                  classes=len(target_subset), \n",
    "                                                                                  subset_classes=target_subset)\n",
    "target_test = torch.utils.data.TensorDataset(torch.stack(target_test_subset_samples), torch.LongTensor(target_labels))\n",
    "\n",
    "\n",
    "full_set = SubsetGuidedDataset(source_test, target_test, num_labeled='all', in_indicies = source_class_indicies, out_indicies = target_class_indicies)\n",
    "\n",
    "\n",
    "XY_test_sampler = PairedSubsetSampler(full_set, subsetsize=1, weight=SUBSET_WEIGHTS)\n",
    "\n",
    "m_data, s_data = get_loader_stats(XY_test_sampler, use_Y=True, batch_size=100, verbose=True)\n",
    "\n",
    "m_data.shape, s_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T09:29:56.959462Z",
     "iopub.status.busy": "2024-05-28T09:29:56.959033Z",
     "iopub.status.idle": "2024-05-28T09:30:00.688042Z",
     "shell.execute_reply": "2024-05-28T09:30:00.687146Z",
     "shell.execute_reply.started": "2024-05-28T09:29:56.959441Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.tools import weights_init_D\n",
    "\n",
    "from src.cunet import CUNet\n",
    "from src.enot import SDE\n",
    "from src.resnet2 import ResNet_D\n",
    "\n",
    "SDEs, BETA_NETs = [], []\n",
    "SDE_OPTs, BETA_NET_OPTs = [], []\n",
    "SDE_SCHEDULERs, BETA_NET_SCHEDULERs = [], []\n",
    "\n",
    "for i in range(len(PIVOTAL_LIST) * 2 - 2):\n",
    "    sde = CUNet(\n",
    "        CHANNELS, CHANNELS, TIME_DIM, base_factor=UNET_BASE_FACTOR\n",
    "    ).cuda()\n",
    "\n",
    "    sde = SDE(\n",
    "        shift_model=sde,\n",
    "        epsilon=EPSILON,\n",
    "        n_steps=N_STEPS,\n",
    "        time_dim=TIME_DIM,\n",
    "        n_last_steps_without_noise=N_LAST_STEPS_WITHOUT_NOISE,\n",
    "        use_positional_encoding=USE_POSITIONAL_ENCODING,\n",
    "        use_gradient_checkpoint=USE_GRADIENT_CHECKPOINT,\n",
    "        predict_shift=PREDICT_SHIFT,\n",
    "        image_input=IMAGE_INPUT,\n",
    "    ).cuda()\n",
    "    SDEs.append(sde)\n",
    "\n",
    "    beta_net = ResNet_D(IMG_SIZE, nc=CHANNELS).cuda()\n",
    "    beta_net.apply(weights_init_D)\n",
    "    BETA_NETs.append(beta_net)\n",
    "\n",
    "\n",
    "if len(DEVICE_IDS) > 1:\n",
    "    for i in range(len(SDEs)):\n",
    "        SDEs[i] = nn.DataParallel(SDEs[i], device_ids=DEVICE_IDS)\n",
    "        BETA_NETs[i] = nn.DataParallel(BETA_NETs[i], device_ids=DEVICE_IDS)\n",
    "\n",
    "        print(\"T params:\", np.sum([np.prod(p.shape) for p in SDEs[0].parameters()]))\n",
    "        print(\n",
    "            \"D params:\", np.sum([np.prod(p.shape) for p in BETA_NETs[0].parameters()])\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T09:30:00.688996Z",
     "iopub.status.busy": "2024-05-28T09:30:00.688830Z",
     "iopub.status.idle": "2024-05-28T09:30:01.780845Z",
     "shell.execute_reply": "2024-05-28T09:30:01.780179Z",
     "shell.execute_reply.started": "2024-05-28T09:30:00.688981Z"
    }
   },
   "outputs": [],
   "source": [
    "# CKPT_DIR = os.path.join(LOAD_PATH, \"iter5000/\")\n",
    "CKPT_DIR = LOAD_PATH\n",
    "for i, sde in enumerate(SDEs):\n",
    "    path = os.path.join(CKPT_DIR, f\"sde{i}.pt\")\n",
    "    print(f\"{path = }\")\n",
    "    sde.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trans example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fixed, Y_fixed = XY_test_sampler.sample()\n",
    "X_fixed, Y_fixed = X_fixed.flatten(start_dim=0, end_dim=1), Y_fixed.flatten(start_dim=0, end_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FID, accuracies, fig = plot_transport_results(X_fixed, \n",
    "                                              Y_fixed, \n",
    "                                              SDEs, \n",
    "                                              m_data,\n",
    "                                              s_data,\n",
    "                                              XY_test_sampler, \n",
    "                                              classifier,\n",
    "                                              metrics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exp result logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Strategy|P List|Iteration|EPSILON|FID|\n",
    "|---|---|---|---|---|\n",
    "|Fix | 0 50 100 | 2000 | 0 | 32.893237846423915 |\n",
    "|Adapt | 0 50 100 | 2000 | 0 | 46.39155850464904 |\n",
    "|Fix | 0 50 100 | 5000 | 0 | 38.80040275352846 |\n",
    "|Adapt | 0 20 50 100 | 2000 | 0 | 41.630040873129474|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACC\n",
    "\n",
    "TODO:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
