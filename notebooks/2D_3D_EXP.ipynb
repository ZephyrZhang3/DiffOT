{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toy Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import trange\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from src import distributions\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "# torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### network generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net(n_inputs, n_outputs, n_layers=3, n_hiddens=100):\n",
    "    layers = [nn.Linear(n_inputs, n_hiddens), nn.ReLU()]\n",
    "\n",
    "    for i in range(n_layers - 1):\n",
    "        layers.extend([nn.Linear(n_hiddens, n_hiddens), nn.ReLU()])\n",
    "\n",
    "    layers.append(nn.Linear(n_hiddens, n_outputs))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "class SDE(nn.Module):\n",
    "    def __init__(self, shift_model, epsilon, n_steps):\n",
    "        super().__init__()\n",
    "        self.shift_model = shift_model\n",
    "        self.noise_std = math.sqrt(epsilon)\n",
    "        self.n_steps = n_steps\n",
    "        self.delta_t = 1 / n_steps\n",
    "\n",
    "    def forward(self, x0):\n",
    "        t0 = 0\n",
    "        trajectory = [x0]\n",
    "        times = [t0]\n",
    "        shifts = []\n",
    "\n",
    "        x, t = x0, t0\n",
    "\n",
    "        for step in range(self.n_steps):\n",
    "            x, t, shift = self._step(x, t)\n",
    "\n",
    "            trajectory.append(x)\n",
    "            times.append(t)\n",
    "            shifts.append(shift)\n",
    "\n",
    "        return (\n",
    "            torch.stack(trajectory, dim=1),\n",
    "            torch.tensor(times, device=x0.device),\n",
    "            torch.stack(shifts, dim=1),\n",
    "        )\n",
    "\n",
    "    def _step(self, x, t):\n",
    "        shift = self._get_shift(x, t)\n",
    "        noise = self._sample_noise(x)\n",
    "\n",
    "        return x + self.delta_t * shift + noise, t + self.delta_t, shift\n",
    "\n",
    "    def _get_shift(self, x, t):\n",
    "        batch_size = x.shape[0]\n",
    "        t = torch.tensor(t).repeat(batch_size).to(device=x.device)\n",
    "\n",
    "        inp = torch.cat((x, t[:, None]), dim=-1)\n",
    "        return self.shift_model(inp)\n",
    "\n",
    "    def _sample_noise(self, x):\n",
    "        noise = self.noise_std * math.sqrt(self.delta_t) * (torch.randn(x.shape))\n",
    "        return noise.to(x.device)\n",
    "\n",
    "    def set_n_steps(self, n_steps):\n",
    "        self.n_steps = n_steps\n",
    "        self.delta_t = 1 / n_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data and pivotal sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler\n",
    "\n",
    "\n",
    "# 采样关键点\n",
    "def sample_all_pivotal(\n",
    "    source_sampler: distributions.Sampler,\n",
    "    target_sampler: distributions.Sampler,\n",
    "    batch_size: int = 1024,\n",
    "    half_steps: int = 1000,\n",
    "    pivotal_list: list[int] = [0, 10, 20, 50],\n",
    ") -> list:\n",
    "    scheduler = DDIMScheduler(num_train_timesteps=half_steps)\n",
    "    pivotal_path = []\n",
    "\n",
    "    source: torch.Tensor = source_sampler.sample(batch_size)\n",
    "    target: torch.Tensor = target_sampler.sample(batch_size)\n",
    "    source_list = [source]\n",
    "    target_list = [target]\n",
    "    for i in range(min(half_steps, pivotal_list[-1])):\n",
    "        source = scheduler.add_noise(\n",
    "            source, torch.randn_like(source), torch.Tensor([i]).long()\n",
    "        )\n",
    "        target = scheduler.add_noise(\n",
    "            target, torch.randn_like(target), torch.Tensor([i]).long()\n",
    "        )\n",
    "        if (i + 1) in pivotal_list:\n",
    "            source_list.append(source)\n",
    "            target_list.append(target)\n",
    "\n",
    "    target_list.reverse()\n",
    "\n",
    "    pivotal_path.extend(source_list)\n",
    "    pivotal_path.extend(target_list[1:])\n",
    "\n",
    "    return pivotal_path\n",
    "\n",
    "\n",
    "def sample_step_t_pivotal(\n",
    "    source_sampler: distributions.Sampler,\n",
    "    target_sampler: distributions.Sampler,\n",
    "    batch_size: int = 1024,\n",
    "    half_steps: int = 1000,\n",
    "    pivotal_list: list[int] = [50, 100, 200, 500],\n",
    "    pivotal_step: int = 0,\n",
    "):\n",
    "    pivotal_path = sample_all_pivotal(\n",
    "        source_sampler, target_sampler, batch_size, half_steps, pivotal_list\n",
    "    )\n",
    "    pivotal_t, pivotal_tadd1 = (\n",
    "        pivotal_path[pivotal_step],\n",
    "        pivotal_path[pivotal_step + 1],\n",
    "    )\n",
    "    return pivotal_t, pivotal_tadd1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapping plotters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(source_dataset, target_dataset, mapped_dataset):\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    datasets = [source_dataset, target_dataset, mapped_dataset]\n",
    "    titles = [\"Input distribution\", \"Target distribution\", \"Fitted distribution\"]\n",
    "    for i, (dataset, title) in enumerate(zip(datasets, titles)):\n",
    "        dim = dataset.shape[-1]\n",
    "\n",
    "        x = dataset.numpy()[:, 0]\n",
    "        y = dataset.numpy()[:, 1]\n",
    "        # color setting\n",
    "        # num_points = x.shape[0]\n",
    "        # colors = [(i / num_points) for i in range(num_points)]\n",
    "        # Calculate the angles for color mapping\n",
    "        angles = np.arctan2(y, x)\n",
    "        normalized_angles = (angles + np.pi) / (\n",
    "            2 * np.pi\n",
    "        )  # Normalize angles between 0 and 1\n",
    "        # Apply a smooth transition function for colors\n",
    "        colors = 0.5 * (1 + np.sin(2 * np.pi * normalized_angles - np.pi / 2))\n",
    "\n",
    "        if dim == 2:\n",
    "            ax = fig.add_subplot(1, 3, i + 1)\n",
    "            ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=colors,  # Apply smooth color transition\n",
    "                cmap=\"rainbow\",  # Use rainbow colormap\n",
    "                s=10,  # Point size\n",
    "                edgecolors=\"none\",  # Remove point borders\n",
    "            )\n",
    "        if dim == 3:\n",
    "            z = dataset.numpy()[:, 2]\n",
    "            ax = fig.add_subplot(1, 3, i + 1, projection=\"3d\")\n",
    "            ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                z,\n",
    "                c=colors,  # Apply smooth color transition\n",
    "                cmap=\"rainbow\",  # Use rainbow colormap\n",
    "                s=10,  # Point size\n",
    "                edgecolors=\"none\",  # Remove point borders\n",
    "            )\n",
    "        ax.set_title(title)\n",
    "        ax.grid()\n",
    "        ax.set_axis_off()\n",
    "        # axes[i].set_xlim([-2.5, 2.5])\n",
    "        # axes[i].set_ylim([-2.5, 2.5])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def draw_sub_mapping(\n",
    "    plot_n_samples,\n",
    "    source_sampler,\n",
    "    target_sampler,\n",
    "    half_steps,\n",
    "    pivotal_list,\n",
    "    pivotal_step,\n",
    "    batch_size,\n",
    "    sde: torch.nn.Module,\n",
    "    img_path: None,\n",
    "):\n",
    "    clear_output()\n",
    "    device = next(sde.parameters()).device\n",
    "    source_dataset, target_dataset, mapped_dataset = [], [], []\n",
    "    for i in range(plot_n_samples // batch_size + 1):\n",
    "        source, target = sample_step_t_pivotal(\n",
    "            source_sampler,\n",
    "            target_sampler,\n",
    "            batch_size,\n",
    "            half_steps,\n",
    "            pivotal_list,\n",
    "            pivotal_step,\n",
    "        )\n",
    "\n",
    "        source = source.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        trajectory, times, _ = sde(source)\n",
    "        xN = trajectory[:, -1, :]\n",
    "\n",
    "        mapped_dataset.append(xN)\n",
    "        source_dataset.append(source)\n",
    "        target_dataset.append(target)\n",
    "\n",
    "    source_dataset, target_dataset, mapped_dataset = (\n",
    "        torch.cat(source_dataset[:plot_n_samples]).cpu(),\n",
    "        torch.cat(target_dataset[:plot_n_samples]).cpu(),\n",
    "        torch.cat(mapped_dataset[:plot_n_samples]).cpu(),\n",
    "    )\n",
    "    plot_results(source_dataset, target_dataset, mapped_dataset)\n",
    "    if img_path:\n",
    "        plt.savefig(img_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def draw_linked_mapping(\n",
    "    plot_n_samples,\n",
    "    source_sampler,\n",
    "    target_sampler,\n",
    "    batch_size,\n",
    "    half_steps,\n",
    "    pivotal_list,\n",
    "    SDEs: list[torch.nn.Module],\n",
    "    img_path: None,\n",
    "):\n",
    "    device = next(SDEs[0].parameters()).device\n",
    "    source_dataset, target_dataset, mapped_dataset = [], [], []\n",
    "    for i in range(plot_n_samples // batch_size + 1):\n",
    "        source, target = (\n",
    "            source_sampler.sampler(batch_size).to(device),\n",
    "            target_sampler.sample(batch_size).to(device),\n",
    "        )\n",
    "\n",
    "        # TODO: 可视化 linked mapping 中的所有 pivotal\n",
    "        pivotals = [source.clone().detach()]\n",
    "        for t in range(len(SDEs)):\n",
    "            x0 = pivotals[t]\n",
    "            trajectory, times, _ = SDEs[t](x0)\n",
    "            xN = trajectory[:, -1, :]\n",
    "            pivotals.append(xN)\n",
    "\n",
    "        mapped_dataset.append(pivotals[-1])\n",
    "        source_dataset.append(source)\n",
    "        target_dataset.append(target)\n",
    "\n",
    "    source_dataset, target_dataset, mapped_dataset = (\n",
    "        torch.cat(source_dataset[:plot_n_samples]).cpu(),\n",
    "        torch.cat(target_dataset[:plot_n_samples]).cpu(),\n",
    "        torch.cat(mapped_dataset[:plot_n_samples]).cpu(),\n",
    "    )\n",
    "\n",
    "    plot_results(source_dataset, target_dataset, mapped_dataset)\n",
    "    if img_path:\n",
    "        plt.savefig(img_path)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 采样关键点\n",
    "def sample_and_draw_all_pivotal(\n",
    "    source_sampler: distributions.Sampler,\n",
    "    target_sampler: distributions.Sampler,\n",
    "    batch_size: int = 1024,\n",
    "    half_steps: int = 1000,\n",
    "    pivotal_list: list[int] = [50, 100, 200, 500],\n",
    ") -> list:\n",
    "    scheduler = DDIMScheduler(num_train_timesteps=half_steps)\n",
    "    pivotal_path = []\n",
    "\n",
    "    source: torch.Tensor = source_sampler.sample(batch_size)\n",
    "    target: torch.Tensor = target_sampler.sample(batch_size)\n",
    "\n",
    "    source_list = [source]\n",
    "    target_list = [target]\n",
    "    for i in range(min(half_steps, pivotal_list[-1])):\n",
    "        source = scheduler.add_noise(\n",
    "            source, torch.randn_like(source), torch.Tensor([i]).long()\n",
    "        )\n",
    "        target = scheduler.add_noise(\n",
    "            target, torch.randn_like(target), torch.Tensor([i]).long()\n",
    "        )\n",
    "        if (i + 1) in pivotal_list:\n",
    "            source_list.append(source)\n",
    "            target_list.append(target)\n",
    "\n",
    "    target_list.reverse()\n",
    "\n",
    "    pivotal_path.extend(source_list)\n",
    "    pivotal_path.extend(target_list)\n",
    "\n",
    "    ncols = len(pivotal_list)\n",
    "    fig = plt.figure(figsize=(5 * ncols, 10))\n",
    "    for i, pivotal in enumerate(pivotal_path):\n",
    "        dim = pivotal.shape[-1]\n",
    "        points = pivotal.numpy()\n",
    "        x, y = points[:, 0], points[:, 1]\n",
    "        # color setting\n",
    "        # num_points = x.shape[0]\n",
    "        # colors = [(i / num_points) for i in range(num_points)]\n",
    "        # Calculate the angles for color mapping\n",
    "        angles = np.arctan2(y, x)\n",
    "        normalized_angles = (angles + np.pi) / (\n",
    "            2 * np.pi\n",
    "        )  # Normalize angles between 0 and 1\n",
    "        # Apply a smooth transition function for colors\n",
    "        colors = 0.5 * (1 + np.sin(2 * np.pi * normalized_angles - np.pi / 2))\n",
    "\n",
    "        if dim == 3:\n",
    "            z = points[:, 2]\n",
    "            ax = fig.add_subplot(2, ncols, i + 1, projection=\"3d\")\n",
    "            ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                z,\n",
    "                c=colors,\n",
    "                cmap=\"rainbow\",\n",
    "                s=10,\n",
    "                edgecolors=\"none\",\n",
    "            )\n",
    "        if dim == 2:\n",
    "            ax = fig.add_subplot(2, ncols, i + 1)\n",
    "            ax.scatter(\n",
    "                x,\n",
    "                y,\n",
    "                c=colors,\n",
    "                cmap=\"rainbow\",\n",
    "                s=10,\n",
    "                edgecolors=\"none\",\n",
    "            )\n",
    "        ax.set_title(f\"x{i} distribution\")\n",
    "        ax.grid(False)\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # return pivotal_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(values, times):\n",
    "    deltas = times[1:] - times[:-1]\n",
    "    return (values * deltas[None, :]).sum(dim=1)\n",
    "\n",
    "\n",
    "def train_linked_mapping(\n",
    "    source_sampler: distributions.Sampler,\n",
    "    target_sampler: distributions.Sampler,\n",
    "    SDEs: list[SDE],\n",
    "    SDE_OPTs: list[torch.optim.Optimizer],\n",
    "    BETA_NETs: list[torch.nn.Module],\n",
    "    BETA_NET_OPTs: list[torch.optim.Optimizer],\n",
    "    iterations: int,\n",
    "    inner_iterations: int,\n",
    "    half_steps: int = 1000,\n",
    "    pivotal_list: list[int] = [0, 10, 20, 50],\n",
    "    batch_size: int = 1024,\n",
    "    device: torch.device = torch.device(\"cpu\"),\n",
    "):\n",
    "    T = len(pivotal_list) * 2 - 2\n",
    "    NORMs: list[list] = []\n",
    "\n",
    "    # 1. 迭代训练ENOT(X_t-1, X_t)\n",
    "    for t in range(T):\n",
    "        norms = []\n",
    "        integral_scale = 1\n",
    "        # a. 选择mapping网络和优化器\n",
    "        sde, beta_net, sde_opt, beta_net_opt = (\n",
    "            SDEs[t],\n",
    "            BETA_NETs[t],\n",
    "            SDE_OPTs[t],\n",
    "            BETA_NET_OPTs[t],\n",
    "        )\n",
    "        for iteration in trange(iterations):\n",
    "            if iteration % 100 == 0:\n",
    "                draw_sub_mapping(\n",
    "                    1024,\n",
    "                    source_sampler,\n",
    "                    target_sampler,\n",
    "                    half_steps,\n",
    "                    pivotal_list,\n",
    "                    t,\n",
    "                    batch_size,\n",
    "                    sde,\n",
    "                    img_path=f\"./logs_plist_without_g2g/sub_mapping_{t}to{t+1}_{iteration}iter.png\",\n",
    "                )\n",
    "            # b. 生成训练数据\n",
    "            source, target = sample_step_t_pivotal(\n",
    "                source_sampler,\n",
    "                target_sampler,\n",
    "                batch_size,\n",
    "                half_steps,\n",
    "                pivotal_list,\n",
    "                t,\n",
    "            )\n",
    "            source = source.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # print(\n",
    "            #     f\"[Debug] {device = } {source.device = } {target.device = } {next(sde.parameters()).device = } {next(beta_net.parameters()).device = }\"\n",
    "            # )\n",
    "\n",
    "            # c. 训练网络\n",
    "            trajectory, times, shifts = sde(source)\n",
    "            target_predicted = trajectory[:, -1, :]\n",
    "\n",
    "            norm = torch.norm(shifts, p=2, dim=-1) ** 2\n",
    "            norms.append(norm)\n",
    "\n",
    "            integral = integral_scale * integrate(norm, times)\n",
    "\n",
    "            loss_beta = (\n",
    "                -integral - beta_net(target) + beta_net(target_predicted)\n",
    "            ).mean()\n",
    "            beta_net_opt.zero_grad()\n",
    "            loss_beta.backward()\n",
    "            beta_net_opt.step()\n",
    "\n",
    "            for inner_iteration in range(inner_iterations):\n",
    "                source, target = sample_step_t_pivotal(\n",
    "                    source_sampler,\n",
    "                    target_sampler,\n",
    "                    batch_size,\n",
    "                    half_steps,\n",
    "                    pivotal_list,\n",
    "                    t,\n",
    "                )\n",
    "                source = source.to(device)\n",
    "                target = target.to(device)\n",
    "                trajectory, times, shifts = sde(source)\n",
    "                target_predicted = trajectory[:, -1, :]\n",
    "\n",
    "                norm = torch.norm(shifts, p=2, dim=-1) ** 2\n",
    "                integral = integral_scale * integrate(norm, times)\n",
    "\n",
    "                loss_sde = (\n",
    "                    integral + beta_net(target) - beta_net(target_predicted)\n",
    "                ).mean()\n",
    "                sde_opt.zero_grad()\n",
    "                loss_sde.backward()\n",
    "                sde_opt.step()\n",
    "\n",
    "        NORMs.append(norms)\n",
    "\n",
    "    draw_linked_mapping(\n",
    "        1024,\n",
    "        source_sampler,\n",
    "        target_sampler,\n",
    "        batch_size,\n",
    "        half_steps,\n",
    "        pivotal_list,\n",
    "        SDEs,\n",
    "        img_path=\"./logs_plist_without_g2g/linked_mapping.png\",\n",
    "    )\n",
    "    # 5. 返回\n",
    "    return SDEs, BETA_NETs, NORMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "target_data_type is \"8_gaussians\" or \"swiss_roll\" depending on the target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEVICE_IDS = [0, 1, 2, 3]\n",
    "# device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "SEED = 0xBADBEEF\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "half_steps = 1000\n",
    "pivotal_list = [0, 10, 20, 50]\n",
    "\n",
    "\n",
    "batch_size = 512\n",
    "iterations = 2000\n",
    "inner_iterations = 10\n",
    "\n",
    "epsilon = 0.1\n",
    "lr = 1e-4\n",
    "n_steps = 10\n",
    "\n",
    "# \"8_gaussians\" or \"swiss_roll\"\n",
    "source_data_type = \"swiss_roll\"\n",
    "target_data_type = \"Mobius\"\n",
    "dim = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initalize data sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据/采样器\n",
    "if source_data_type == \"swiss_roll\":\n",
    "    source_sampler = distributions.SwissRollSampler(device=\"cpu\", dim=dim)\n",
    "elif source_data_type == \"8_gaussians\":\n",
    "    source_sampler = distributions.Mix8GaussiansSampler(\n",
    "        std=0.1, r=math.sqrt(2), device=\"cpu\"\n",
    "    )\n",
    "elif source_data_type == \"moons\":\n",
    "    source_sampler = distributions.MoonsSampler(device=\"cpu\")\n",
    "elif source_data_type == \"Mobius\":\n",
    "    source_sampler = distributions.MobiusStripSampler(device=\"cpu\")\n",
    "\n",
    "if target_data_type == \"swiss_roll\":\n",
    "    target_sampler = distributions.SwissRollSampler(device=\"cpu\", dim=dim)\n",
    "elif target_data_type == \"8_gaussians\":\n",
    "    target_sampler = distributions.Mix8GaussiansSampler(\n",
    "        std=0.1, r=math.sqrt(2), device=\"cpu\"\n",
    "    )\n",
    "elif target_data_type == \"moons\":\n",
    "    target_sampler = distributions.MoonsSampler(device=\"cpu\")\n",
    "elif target_data_type == \"Mobius\":\n",
    "    target_sampler = distributions.MobiusStripSampler(device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### show sample data and pivotals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_and_draw_all_pivotal(\n",
    "    source_sampler, target_sampler, batch_size=5000, pivotal_list=[0, 10, 20, 50, 100]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initalize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备映射网络与优化器\n",
    "SDEs, BETA_NETs = [], []\n",
    "SDE_OPTs, BETA_NET_OPTs = [], []\n",
    "\n",
    "for i in range(len(pivotal_list) * 2 - 2):\n",
    "    sde_shift_model = make_net(\n",
    "        n_inputs=dim + 1, n_outputs=dim, n_layers=3, n_hiddens=100\n",
    "    ).to(device)\n",
    "    sde = SDE(sde_shift_model, epsilon, n_steps).to(device)\n",
    "    SDEs.append(sde)\n",
    "\n",
    "    beta_net = make_net(n_inputs=dim, n_outputs=1, n_layers=3, n_hiddens=100).to(device)\n",
    "    BETA_NETs.append(beta_net)\n",
    "\n",
    "    sde_opt = Adam(sde.parameters(), lr=lr)\n",
    "    beta_net_opt = Adam(beta_net.parameters(), lr=lr)\n",
    "    SDE_OPTs.append(sde_opt)\n",
    "    BETA_NET_OPTs.append(beta_net_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练网络\n",
    "SDEs, BETA_NETs, NORMs = train_linked_mapping(\n",
    "    source_sampler,\n",
    "    target_sampler,\n",
    "    SDEs,\n",
    "    SDE_OPTs,\n",
    "    BETA_NETs,\n",
    "    BETA_NET_OPTs,\n",
    "    iterations,\n",
    "    inner_iterations,\n",
    "    half_steps,\n",
    "    pivotal_list,\n",
    "    batch_size,\n",
    "    device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "\n",
    "path = f\"../toy_sde_models/pivotal_{'_'.join(map(str, pivotal_list))}\"\n",
    "print(f\"[Info] saving {path = }\")\n",
    "for i, sde in enumerate(SDEs):\n",
    "    torch.save(\n",
    "        sde.state_dict(),\n",
    "        os.path.join(\n",
    "            path, f\"sde{i}_{source_data_type}_{target_data_type}_{epsilon}_{n_steps}.pt\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "def load_sdes(path: str) -> list[SDE]:\n",
    "    num = len(glob(os.path.join(path, \"*.pt\")))\n",
    "    SDEs = []\n",
    "    for i in range(num):\n",
    "        sde_path = os.path.join(\n",
    "            path, f\"sde{i}_{source_data_type}_{target_data_type}_{epsilon}_{n_steps}.pt\"\n",
    "        )\n",
    "        print(sde_path)\n",
    "        sde_shift_model = make_net(\n",
    "            n_inputs=2 + 1, n_outputs=2, n_layers=3, n_hiddens=100\n",
    "        )\n",
    "        sde = SDE(shift_model=sde_shift_model, epsilon=epsilon, n_steps=n_steps)\n",
    "        sde.load_state_dict(torch.load(sde_path))\n",
    "        SDEs.append(sde)\n",
    "\n",
    "    return SDEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TODO: Current model plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "plot_n_samples = 1024\n",
    "\n",
    "mapped_dataset = map_dataset(sde, source_sampler, batch_size, plot_n_samples)\n",
    "source_dataset = torch.cat(\n",
    "    [\n",
    "        source_sampler.sample(batch_size)\n",
    "        for i in range(plot_n_samples // batch_size + 1)\n",
    "    ],\n",
    "    dim=0,\n",
    ")[:plot_n_samples].cpu()\n",
    "target_dataset = torch.cat(\n",
    "    [\n",
    "        target_sampler.sample(batch_size)\n",
    "        for i in range(plot_n_samples // batch_size + 1)\n",
    "    ],\n",
    "    dim=0,\n",
    ")[:plot_n_samples].cpu()\n",
    "\n",
    "plot_results(source_dataset, target_dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = sde(source_sampler.sample(64)[:64])[0].detach().cpu()\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(\n",
    "        tr[i, :, 0],\n",
    "        tr[i, :, 1],\n",
    "        \"-o\",\n",
    "        markeredgecolor=\"black\",\n",
    "        linewidth=4,\n",
    "        markersize=4,\n",
    "    )\n",
    "\n",
    "target_dataset = target_sampler.sample(750).cpu().numpy()\n",
    "plt.scatter(\n",
    "    target_dataset[:, 0],\n",
    "    target_dataset[:, 1],\n",
    "    c=\"orange\",\n",
    "    s=20,\n",
    "    edgecolors=\"black\",\n",
    "    label=\"target data\",\n",
    ")\n",
    "plt.title(\"Trajectories\")\n",
    "\n",
    "plt.grid()\n",
    "plt.xlim([-2.5, 2.5])\n",
    "plt.ylim([-2.5, 2.5])\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. TODO: Final plots for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [0, 0.01, 0.1]\n",
    "path = \"../toy_sde_models/\"\n",
    "\n",
    "source_sampler = distributions.StandardNormalSampler(dim=2, device=\"cpu\")\n",
    "\n",
    "if target_data_type == \"swiss_roll\":\n",
    "    target_sampler = distributions.SwissRollSampler(device=\"cpu\")\n",
    "elif target_data_type == \"8_gaussians\":\n",
    "    target_sampler = distributions.Mix8GaussiansSampler(\n",
    "        std=0.1, r=math.sqrt(2), device=\"cpu\"\n",
    "    )\n",
    "\n",
    "sdes = []\n",
    "for epsilon in epsilons:\n",
    "    sde_shift_model = make_net(n_inputs=2 + 1, n_outputs=2, n_layers=3, n_hiddens=100)\n",
    "    sde = SDE(shift_model=sde_shift_model, epsilon=epsilon, n_steps=n_steps)\n",
    "    sde.load_state_dict(\n",
    "        torch.load(os.path.join(path, f\"sde_{target_data_type}_{epsilon}_{n_steps}.pt\"))\n",
    "    )\n",
    "    print(os.path.join(path, f\"sde_{target_data_type}_{epsilon}_{n_steps}.pt\"))\n",
    "    sdes.append(sde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_n_samples = 600\n",
    "\n",
    "source_dataset = torch.cat(\n",
    "    [\n",
    "        source_sampler.sample(batch_size)\n",
    "        for i in range(plot_n_samples // batch_size + 1)\n",
    "    ],\n",
    "    dim=0,\n",
    ")[:plot_n_samples].cpu()\n",
    "target_dataset = torch.cat(\n",
    "    [\n",
    "        target_sampler.sample(batch_size)\n",
    "        for i in range(plot_n_samples // batch_size + 1)\n",
    "    ],\n",
    "    dim=0,\n",
    ")[:plot_n_samples].cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(25, 10), dpi=450)\n",
    "axes[0, 0].scatter(\n",
    "    source_dataset.numpy()[:, 0],\n",
    "    source_dataset.numpy()[:, 1],\n",
    "    c=\"g\",\n",
    "    s=48,\n",
    "    edgecolors=\"black\",\n",
    ")\n",
    "axes[0, 0].set_title(\"Input distribution\")\n",
    "\n",
    "axes[1, 0].scatter(\n",
    "    target_dataset.numpy()[:, 0],\n",
    "    target_dataset.numpy()[:, 1],\n",
    "    c=\"orange\",\n",
    "    s=48,\n",
    "    edgecolors=\"black\",\n",
    ")\n",
    "axes[1, 0].set_title(\"Target distribution\")\n",
    "\n",
    "for n, (sde, epsilon) in enumerate(zip(sdes, epsilons)):\n",
    "    n = n + 1\n",
    "    mapped_dataset = map_dataset(sde, source_dataset, plot_n_samples=plot_n_samples)\n",
    "    axes[0, n].scatter(\n",
    "        mapped_dataset.numpy()[:, 0],\n",
    "        mapped_dataset.numpy()[:, 1],\n",
    "        c=\"yellow\",\n",
    "        s=48,\n",
    "        edgecolors=\"black\",\n",
    "    )\n",
    "    axes[0, n].set_title(\"Fitted distribution $\\epsilon=$ \" + f\"{epsilon}\")\n",
    "\n",
    "    tr = sde(source_dataset[:20])[0].detach()\n",
    "\n",
    "    for i in range(20):\n",
    "        axes[1, n].plot(\n",
    "            tr[i, :, 0],\n",
    "            tr[i, :, 1],\n",
    "            \"-o\",\n",
    "            markeredgecolor=\"black\",\n",
    "            c=\"green\",\n",
    "            linewidth=3,\n",
    "            markersize=4,\n",
    "            markeredgewidth=0.5,\n",
    "        )\n",
    "\n",
    "    axes[1, n].scatter(\n",
    "        target_dataset.numpy()[:, 0],\n",
    "        target_dataset.numpy()[:, 1],\n",
    "        c=\"orange\",\n",
    "        s=48,\n",
    "        edgecolors=\"black\",\n",
    "        label=\"target data\",\n",
    "    )\n",
    "    axes[1, n].set_title(\"Trajectories $\\epsilon=$ \" + f\"{epsilon}\")\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    axes[i % 2, i // 2].grid()\n",
    "    axes[i % 2, i // 2].set_xlim([-2.5, 2.5])\n",
    "    axes[i % 2, i // 2].set_ylim([-2.5, 2.5])\n",
    "\n",
    "plt.savefig(f\"../pics/{target_data_type}_results.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pictures for the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(3.125 * 0.9, 6.25 * 0.9), dpi=450)\n",
    "axes[0].scatter(\n",
    "    source_dataset.numpy()[:, 0],\n",
    "    source_dataset.numpy()[:, 1],\n",
    "    c=\"g\",\n",
    "    s=48,\n",
    "    edgecolors=\"black\",\n",
    "    label=\"Input distribution\",\n",
    ")\n",
    "axes[0].legend()\n",
    "axes[0].grid()\n",
    "# axes[0, 0].set_title(\"Input distribution\")\n",
    "\n",
    "axes[1].scatter(\n",
    "    target_dataset.numpy()[:, 0],\n",
    "    target_dataset.numpy()[:, 1],\n",
    "    c=\"orange\",\n",
    "    s=48,\n",
    "    edgecolors=\"black\",\n",
    "    label=\"Target distribution\",\n",
    ")\n",
    "axes[1].legend()\n",
    "axes[1].grid()\n",
    "fig.tight_layout(pad=0.1)\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i % 2].set_xlim([-2.5, 2.5])\n",
    "    axes[i % 2].set_ylim([-2.5, 2.5])\n",
    "\n",
    "plt.savefig(f\"../pics/{target_data_type}_results_input_and_target.jpg\")\n",
    "\n",
    "for n, (sde, epsilon) in enumerate(zip(sdes, epsilons)):\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(3.125 * 0.9, 6.25 * 0.9), dpi=450)\n",
    "    #     n = n+1\n",
    "    mapped_dataset = map_dataset(sde, source_dataset, plot_n_samples=plot_n_samples)\n",
    "\n",
    "    axes[0].scatter(\n",
    "        mapped_dataset.numpy()[:, 0],\n",
    "        mapped_dataset.numpy()[:, 1],\n",
    "        c=\"yellow\",\n",
    "        s=48,\n",
    "        edgecolors=\"black\",\n",
    "        label=\"Fitted distribution\",\n",
    "    )\n",
    "    axes[0].legend()\n",
    "\n",
    "    tr = sde(source_dataset[:20])[0].detach()\n",
    "\n",
    "    n_traj = 20 if epsilon < 1 else 5\n",
    "    for i in range(n_traj):\n",
    "        if i == 0:\n",
    "            axes[1].plot(\n",
    "                tr[i, :, 0],\n",
    "                tr[i, :, 1],\n",
    "                \"-o\",\n",
    "                markeredgecolor=\"black\",\n",
    "                c=\"green\",\n",
    "                linewidth=3,\n",
    "                markersize=4,\n",
    "                markeredgewidth=0.5,\n",
    "                label=\"Trajectories\",\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            axes[1].plot(\n",
    "                tr[i, :, 0],\n",
    "                tr[i, :, 1],\n",
    "                \"-o\",\n",
    "                markeredgecolor=\"black\",\n",
    "                c=\"green\",\n",
    "                linewidth=3,\n",
    "                markersize=4,\n",
    "                markeredgewidth=0.5,\n",
    "            )\n",
    "\n",
    "    axes[1].scatter(\n",
    "        target_dataset.numpy()[:, 0],\n",
    "        target_dataset.numpy()[:, 1],\n",
    "        c=\"orange\",\n",
    "        s=48,\n",
    "        edgecolors=\"black\",\n",
    "        label=\"Target data\",\n",
    "    )\n",
    "    axes[1].legend()\n",
    "\n",
    "    for i in range(2):\n",
    "        axes[i % 2].grid()\n",
    "        axes[i % 2].set_xlim([-2.5, 2.5])\n",
    "        axes[i % 2].set_ylim([-2.5, 2.5])\n",
    "\n",
    "    fig.tight_layout(pad=0.1)\n",
    "\n",
    "    plt.savefig(f\"../pics/{target_data_type}_results_{epsilon}.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
